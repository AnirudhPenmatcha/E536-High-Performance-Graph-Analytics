{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sklearn.metrics as metrics\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.nn import GATConv"
      ],
      "metadata": {
        "id": "A17xlr3GRcSG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='Cora', name='Cora')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRN_un7VRc1B",
        "outputId": "66f6df4a-6c77-406a-a417-7771b1889dd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Compare GCN, GraphSAGE, and GAT"
      ],
      "metadata": {
        "id": "59fnUWhVOOFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN"
      ],
      "metadata": {
        "id": "9RTVBzMmRMXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URyvFAs8OJpe",
        "outputId": "975dbdce-0307-4b46-dc8c-ae0f0eccd839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.5500\n",
            "Epoch: 1, Accuracy: 0.6643\n",
            "Epoch: 2, Accuracy: 0.7429\n",
            "Epoch: 3, Accuracy: 0.7929\n",
            "Epoch: 4, Accuracy: 0.8214\n",
            "Epoch: 5, Accuracy: 0.8429\n",
            "Epoch: 6, Accuracy: 0.8714\n",
            "Epoch: 7, Accuracy: 0.9000\n",
            "Epoch: 8, Accuracy: 0.9286\n",
            "Epoch: 9, Accuracy: 0.9429\n",
            "Epoch: 10, Accuracy: 0.9571\n",
            "Epoch: 11, Accuracy: 0.9786\n",
            "Epoch: 12, Accuracy: 0.9786\n",
            "Epoch: 13, Accuracy: 0.9857\n",
            "Epoch: 14, Accuracy: 0.9857\n",
            "Epoch: 15, Accuracy: 0.9929\n",
            "Epoch: 16, Accuracy: 1.0000\n",
            "Epoch: 17, Accuracy: 1.0000\n",
            "Epoch: 18, Accuracy: 1.0000\n",
            "Epoch: 19, Accuracy: 1.0000\n",
            "Epoch: 20, Accuracy: 1.0000\n",
            "Epoch: 21, Accuracy: 1.0000\n",
            "Epoch: 22, Accuracy: 1.0000\n",
            "Epoch: 23, Accuracy: 1.0000\n",
            "Epoch: 24, Accuracy: 1.0000\n",
            "Epoch: 25, Accuracy: 1.0000\n",
            "Epoch: 26, Accuracy: 1.0000\n",
            "Epoch: 27, Accuracy: 1.0000\n",
            "Epoch: 28, Accuracy: 1.0000\n",
            "Epoch: 29, Accuracy: 1.0000\n",
            "Epoch: 30, Accuracy: 1.0000\n",
            "Epoch: 31, Accuracy: 1.0000\n",
            "Epoch: 32, Accuracy: 1.0000\n",
            "Epoch: 33, Accuracy: 1.0000\n",
            "Epoch: 34, Accuracy: 1.0000\n",
            "Epoch: 35, Accuracy: 1.0000\n",
            "Epoch: 36, Accuracy: 1.0000\n",
            "Epoch: 37, Accuracy: 1.0000\n",
            "Epoch: 38, Accuracy: 1.0000\n",
            "Epoch: 39, Accuracy: 1.0000\n",
            "Epoch: 40, Accuracy: 1.0000\n",
            "Epoch: 41, Accuracy: 1.0000\n",
            "Epoch: 42, Accuracy: 1.0000\n",
            "Epoch: 43, Accuracy: 1.0000\n",
            "Epoch: 44, Accuracy: 1.0000\n",
            "Epoch: 45, Accuracy: 1.0000\n",
            "Epoch: 46, Accuracy: 1.0000\n",
            "Epoch: 47, Accuracy: 1.0000\n",
            "Epoch: 48, Accuracy: 1.0000\n",
            "Epoch: 49, Accuracy: 1.0000\n",
            "Epoch: 50, Accuracy: 1.0000\n",
            "Epoch: 51, Accuracy: 1.0000\n",
            "Epoch: 52, Accuracy: 1.0000\n",
            "Epoch: 53, Accuracy: 1.0000\n",
            "Epoch: 54, Accuracy: 1.0000\n",
            "Epoch: 55, Accuracy: 1.0000\n",
            "Epoch: 56, Accuracy: 1.0000\n",
            "Epoch: 57, Accuracy: 1.0000\n",
            "Epoch: 58, Accuracy: 1.0000\n",
            "Epoch: 59, Accuracy: 1.0000\n",
            "Epoch: 60, Accuracy: 1.0000\n",
            "Epoch: 61, Accuracy: 1.0000\n",
            "Epoch: 62, Accuracy: 1.0000\n",
            "Epoch: 63, Accuracy: 1.0000\n",
            "Epoch: 64, Accuracy: 1.0000\n",
            "Epoch: 65, Accuracy: 1.0000\n",
            "Epoch: 66, Accuracy: 1.0000\n",
            "Epoch: 67, Accuracy: 1.0000\n",
            "Epoch: 68, Accuracy: 1.0000\n",
            "Epoch: 69, Accuracy: 1.0000\n",
            "Epoch: 70, Accuracy: 1.0000\n",
            "Epoch: 71, Accuracy: 1.0000\n",
            "Epoch: 72, Accuracy: 1.0000\n",
            "Epoch: 73, Accuracy: 1.0000\n",
            "Epoch: 74, Accuracy: 1.0000\n",
            "Epoch: 75, Accuracy: 1.0000\n",
            "Epoch: 76, Accuracy: 1.0000\n",
            "Epoch: 77, Accuracy: 1.0000\n",
            "Epoch: 78, Accuracy: 1.0000\n",
            "Epoch: 79, Accuracy: 1.0000\n",
            "Epoch: 80, Accuracy: 1.0000\n",
            "Epoch: 81, Accuracy: 1.0000\n",
            "Epoch: 82, Accuracy: 1.0000\n",
            "Epoch: 83, Accuracy: 1.0000\n",
            "Epoch: 84, Accuracy: 1.0000\n",
            "Epoch: 85, Accuracy: 1.0000\n",
            "Epoch: 86, Accuracy: 1.0000\n",
            "Epoch: 87, Accuracy: 1.0000\n",
            "Epoch: 88, Accuracy: 1.0000\n",
            "Epoch: 89, Accuracy: 1.0000\n",
            "Epoch: 90, Accuracy: 1.0000\n",
            "Epoch: 91, Accuracy: 1.0000\n",
            "Epoch: 92, Accuracy: 1.0000\n",
            "Epoch: 93, Accuracy: 1.0000\n",
            "Epoch: 94, Accuracy: 1.0000\n",
            "Epoch: 95, Accuracy: 1.0000\n",
            "Epoch: 96, Accuracy: 1.0000\n",
            "Epoch: 97, Accuracy: 1.0000\n",
            "Epoch: 98, Accuracy: 1.0000\n",
            "Epoch: 99, Accuracy: 1.0000\n",
            "Test accuracy for GCNConv: 0.7970\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # you can change convolutions here\n",
        "        #self.conv1 = SAGEConv(dataset.num_node_features, 16)\n",
        "        #self.conv2 = SAGEConv(16, dataset.num_classes)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, pred = model(data).max(dim=1)\n",
        "    correct = float (pred[data.train_mask].eq(data.y[data.train_mask]).sum().item())\n",
        "    acc = correct / data.train_mask.sum().item()\n",
        "    print('Epoch: %d, Accuracy: %.4f'%(epoch,acc))\n",
        "\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print('Test accuracy for GCNConv: {:.4f}'.format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GraphSAGE"
      ],
      "metadata": {
        "id": "Zynjdtm1R3iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # you can change convolutions here\n",
        "        self.conv1 = SAGEConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = SAGEConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, pred = model(data).max(dim=1)\n",
        "    correct = float (pred[data.train_mask].eq(data.y[data.train_mask]).sum().item())\n",
        "    acc = correct / data.train_mask.sum().item()\n",
        "    print('Epoch: %d, Accuracy: %.4f'%(epoch,acc))\n",
        "\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print('Test accuracy for GraphSAGE: {:.4f}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6agjW0LR6Pb",
        "outputId": "19d3d2aa-c069-447e-a678-e796f88ab106"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.7643\n",
            "Epoch: 1, Accuracy: 0.9929\n",
            "Epoch: 2, Accuracy: 1.0000\n",
            "Epoch: 3, Accuracy: 1.0000\n",
            "Epoch: 4, Accuracy: 1.0000\n",
            "Epoch: 5, Accuracy: 1.0000\n",
            "Epoch: 6, Accuracy: 1.0000\n",
            "Epoch: 7, Accuracy: 1.0000\n",
            "Epoch: 8, Accuracy: 1.0000\n",
            "Epoch: 9, Accuracy: 1.0000\n",
            "Epoch: 10, Accuracy: 1.0000\n",
            "Epoch: 11, Accuracy: 1.0000\n",
            "Epoch: 12, Accuracy: 1.0000\n",
            "Epoch: 13, Accuracy: 1.0000\n",
            "Epoch: 14, Accuracy: 1.0000\n",
            "Epoch: 15, Accuracy: 1.0000\n",
            "Epoch: 16, Accuracy: 1.0000\n",
            "Epoch: 17, Accuracy: 1.0000\n",
            "Epoch: 18, Accuracy: 1.0000\n",
            "Epoch: 19, Accuracy: 1.0000\n",
            "Epoch: 20, Accuracy: 1.0000\n",
            "Epoch: 21, Accuracy: 1.0000\n",
            "Epoch: 22, Accuracy: 1.0000\n",
            "Epoch: 23, Accuracy: 1.0000\n",
            "Epoch: 24, Accuracy: 1.0000\n",
            "Epoch: 25, Accuracy: 1.0000\n",
            "Epoch: 26, Accuracy: 1.0000\n",
            "Epoch: 27, Accuracy: 1.0000\n",
            "Epoch: 28, Accuracy: 1.0000\n",
            "Epoch: 29, Accuracy: 1.0000\n",
            "Epoch: 30, Accuracy: 1.0000\n",
            "Epoch: 31, Accuracy: 1.0000\n",
            "Epoch: 32, Accuracy: 1.0000\n",
            "Epoch: 33, Accuracy: 1.0000\n",
            "Epoch: 34, Accuracy: 1.0000\n",
            "Epoch: 35, Accuracy: 1.0000\n",
            "Epoch: 36, Accuracy: 1.0000\n",
            "Epoch: 37, Accuracy: 1.0000\n",
            "Epoch: 38, Accuracy: 1.0000\n",
            "Epoch: 39, Accuracy: 1.0000\n",
            "Epoch: 40, Accuracy: 1.0000\n",
            "Epoch: 41, Accuracy: 1.0000\n",
            "Epoch: 42, Accuracy: 1.0000\n",
            "Epoch: 43, Accuracy: 1.0000\n",
            "Epoch: 44, Accuracy: 1.0000\n",
            "Epoch: 45, Accuracy: 1.0000\n",
            "Epoch: 46, Accuracy: 1.0000\n",
            "Epoch: 47, Accuracy: 1.0000\n",
            "Epoch: 48, Accuracy: 1.0000\n",
            "Epoch: 49, Accuracy: 1.0000\n",
            "Epoch: 50, Accuracy: 1.0000\n",
            "Epoch: 51, Accuracy: 1.0000\n",
            "Epoch: 52, Accuracy: 1.0000\n",
            "Epoch: 53, Accuracy: 1.0000\n",
            "Epoch: 54, Accuracy: 1.0000\n",
            "Epoch: 55, Accuracy: 1.0000\n",
            "Epoch: 56, Accuracy: 1.0000\n",
            "Epoch: 57, Accuracy: 1.0000\n",
            "Epoch: 58, Accuracy: 1.0000\n",
            "Epoch: 59, Accuracy: 1.0000\n",
            "Epoch: 60, Accuracy: 1.0000\n",
            "Epoch: 61, Accuracy: 1.0000\n",
            "Epoch: 62, Accuracy: 1.0000\n",
            "Epoch: 63, Accuracy: 1.0000\n",
            "Epoch: 64, Accuracy: 1.0000\n",
            "Epoch: 65, Accuracy: 1.0000\n",
            "Epoch: 66, Accuracy: 1.0000\n",
            "Epoch: 67, Accuracy: 1.0000\n",
            "Epoch: 68, Accuracy: 1.0000\n",
            "Epoch: 69, Accuracy: 1.0000\n",
            "Epoch: 70, Accuracy: 1.0000\n",
            "Epoch: 71, Accuracy: 1.0000\n",
            "Epoch: 72, Accuracy: 1.0000\n",
            "Epoch: 73, Accuracy: 1.0000\n",
            "Epoch: 74, Accuracy: 1.0000\n",
            "Epoch: 75, Accuracy: 1.0000\n",
            "Epoch: 76, Accuracy: 1.0000\n",
            "Epoch: 77, Accuracy: 1.0000\n",
            "Epoch: 78, Accuracy: 1.0000\n",
            "Epoch: 79, Accuracy: 1.0000\n",
            "Epoch: 80, Accuracy: 1.0000\n",
            "Epoch: 81, Accuracy: 1.0000\n",
            "Epoch: 82, Accuracy: 1.0000\n",
            "Epoch: 83, Accuracy: 1.0000\n",
            "Epoch: 84, Accuracy: 1.0000\n",
            "Epoch: 85, Accuracy: 1.0000\n",
            "Epoch: 86, Accuracy: 1.0000\n",
            "Epoch: 87, Accuracy: 1.0000\n",
            "Epoch: 88, Accuracy: 1.0000\n",
            "Epoch: 89, Accuracy: 1.0000\n",
            "Epoch: 90, Accuracy: 1.0000\n",
            "Epoch: 91, Accuracy: 1.0000\n",
            "Epoch: 92, Accuracy: 1.0000\n",
            "Epoch: 93, Accuracy: 1.0000\n",
            "Epoch: 94, Accuracy: 1.0000\n",
            "Epoch: 95, Accuracy: 1.0000\n",
            "Epoch: 96, Accuracy: 1.0000\n",
            "Epoch: 97, Accuracy: 1.0000\n",
            "Epoch: 98, Accuracy: 1.0000\n",
            "Epoch: 99, Accuracy: 1.0000\n",
            "Test accuracy for GraphSAGE: 0.7620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT"
      ],
      "metadata": {
        "id": "irKGj3LJSXaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # you can change convolutions here\n",
        "        self.conv1 = GATConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GATConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, pred = model(data).max(dim=1)\n",
        "    correct = float (pred[data.train_mask].eq(data.y[data.train_mask]).sum().item())\n",
        "    acc = correct / data.train_mask.sum().item()\n",
        "    print('Epoch: %d, Accuracy: %.4f'%(epoch,acc))\n",
        "\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print('Test accuracy for GAT: {:.4f}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wcn5_RRSaAq",
        "outputId": "5c8c3c91-59b6-4bd5-9f30-52b41c1caa85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.6571\n",
            "Epoch: 1, Accuracy: 0.7571\n",
            "Epoch: 2, Accuracy: 0.8000\n",
            "Epoch: 3, Accuracy: 0.9071\n",
            "Epoch: 4, Accuracy: 0.9214\n",
            "Epoch: 5, Accuracy: 0.9571\n",
            "Epoch: 6, Accuracy: 0.9643\n",
            "Epoch: 7, Accuracy: 0.9714\n",
            "Epoch: 8, Accuracy: 0.9714\n",
            "Epoch: 9, Accuracy: 0.9786\n",
            "Epoch: 10, Accuracy: 0.9786\n",
            "Epoch: 11, Accuracy: 0.9786\n",
            "Epoch: 12, Accuracy: 0.9786\n",
            "Epoch: 13, Accuracy: 0.9786\n",
            "Epoch: 14, Accuracy: 0.9857\n",
            "Epoch: 15, Accuracy: 0.9857\n",
            "Epoch: 16, Accuracy: 0.9857\n",
            "Epoch: 17, Accuracy: 0.9929\n",
            "Epoch: 18, Accuracy: 0.9929\n",
            "Epoch: 19, Accuracy: 1.0000\n",
            "Epoch: 20, Accuracy: 1.0000\n",
            "Epoch: 21, Accuracy: 1.0000\n",
            "Epoch: 22, Accuracy: 1.0000\n",
            "Epoch: 23, Accuracy: 1.0000\n",
            "Epoch: 24, Accuracy: 1.0000\n",
            "Epoch: 25, Accuracy: 1.0000\n",
            "Epoch: 26, Accuracy: 1.0000\n",
            "Epoch: 27, Accuracy: 1.0000\n",
            "Epoch: 28, Accuracy: 1.0000\n",
            "Epoch: 29, Accuracy: 1.0000\n",
            "Epoch: 30, Accuracy: 1.0000\n",
            "Epoch: 31, Accuracy: 1.0000\n",
            "Epoch: 32, Accuracy: 1.0000\n",
            "Epoch: 33, Accuracy: 1.0000\n",
            "Epoch: 34, Accuracy: 1.0000\n",
            "Epoch: 35, Accuracy: 1.0000\n",
            "Epoch: 36, Accuracy: 1.0000\n",
            "Epoch: 37, Accuracy: 1.0000\n",
            "Epoch: 38, Accuracy: 1.0000\n",
            "Epoch: 39, Accuracy: 1.0000\n",
            "Epoch: 40, Accuracy: 1.0000\n",
            "Epoch: 41, Accuracy: 1.0000\n",
            "Epoch: 42, Accuracy: 1.0000\n",
            "Epoch: 43, Accuracy: 1.0000\n",
            "Epoch: 44, Accuracy: 1.0000\n",
            "Epoch: 45, Accuracy: 1.0000\n",
            "Epoch: 46, Accuracy: 1.0000\n",
            "Epoch: 47, Accuracy: 1.0000\n",
            "Epoch: 48, Accuracy: 1.0000\n",
            "Epoch: 49, Accuracy: 1.0000\n",
            "Epoch: 50, Accuracy: 1.0000\n",
            "Epoch: 51, Accuracy: 1.0000\n",
            "Epoch: 52, Accuracy: 1.0000\n",
            "Epoch: 53, Accuracy: 1.0000\n",
            "Epoch: 54, Accuracy: 1.0000\n",
            "Epoch: 55, Accuracy: 1.0000\n",
            "Epoch: 56, Accuracy: 1.0000\n",
            "Epoch: 57, Accuracy: 1.0000\n",
            "Epoch: 58, Accuracy: 1.0000\n",
            "Epoch: 59, Accuracy: 1.0000\n",
            "Epoch: 60, Accuracy: 1.0000\n",
            "Epoch: 61, Accuracy: 1.0000\n",
            "Epoch: 62, Accuracy: 1.0000\n",
            "Epoch: 63, Accuracy: 1.0000\n",
            "Epoch: 64, Accuracy: 1.0000\n",
            "Epoch: 65, Accuracy: 1.0000\n",
            "Epoch: 66, Accuracy: 1.0000\n",
            "Epoch: 67, Accuracy: 1.0000\n",
            "Epoch: 68, Accuracy: 1.0000\n",
            "Epoch: 69, Accuracy: 1.0000\n",
            "Epoch: 70, Accuracy: 1.0000\n",
            "Epoch: 71, Accuracy: 1.0000\n",
            "Epoch: 72, Accuracy: 1.0000\n",
            "Epoch: 73, Accuracy: 1.0000\n",
            "Epoch: 74, Accuracy: 1.0000\n",
            "Epoch: 75, Accuracy: 1.0000\n",
            "Epoch: 76, Accuracy: 1.0000\n",
            "Epoch: 77, Accuracy: 1.0000\n",
            "Epoch: 78, Accuracy: 1.0000\n",
            "Epoch: 79, Accuracy: 1.0000\n",
            "Epoch: 80, Accuracy: 1.0000\n",
            "Epoch: 81, Accuracy: 1.0000\n",
            "Epoch: 82, Accuracy: 1.0000\n",
            "Epoch: 83, Accuracy: 1.0000\n",
            "Epoch: 84, Accuracy: 1.0000\n",
            "Epoch: 85, Accuracy: 1.0000\n",
            "Epoch: 86, Accuracy: 1.0000\n",
            "Epoch: 87, Accuracy: 1.0000\n",
            "Epoch: 88, Accuracy: 1.0000\n",
            "Epoch: 89, Accuracy: 1.0000\n",
            "Epoch: 90, Accuracy: 1.0000\n",
            "Epoch: 91, Accuracy: 1.0000\n",
            "Epoch: 92, Accuracy: 1.0000\n",
            "Epoch: 93, Accuracy: 1.0000\n",
            "Epoch: 94, Accuracy: 1.0000\n",
            "Epoch: 95, Accuracy: 1.0000\n",
            "Epoch: 96, Accuracy: 1.0000\n",
            "Epoch: 97, Accuracy: 1.0000\n",
            "Epoch: 98, Accuracy: 1.0000\n",
            "Epoch: 99, Accuracy: 1.0000\n",
            "Test accuracy for GAT: 0.7330\n"
          ]
        }
      ]
    }
  ]
}